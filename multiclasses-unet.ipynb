{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ludmiladias/multiclasses-unet?scriptVersionId=140818335\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div id=\"title\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:50px;text-align:center\">U-Net Multiclasses Training</h1></div>\n\nProjeto desenvolvido usando a rede de segmentação U-NET, biblioteca Keras e Tensorflow.\nO Road Mapper DNN tem como objetivo gerar mapas de estrada com segmentação das faixas de sinalização utilizada pelos veículos, tendo como entrada mapas de remissão gerados pelo LIDAR - sensor laser que faz parte do sistema de carros autônomos como o ASTRO da Lume Robotics.\n","metadata":{"id":"SscH4lze36iJ"}},{"cell_type":"markdown","source":"Input | Output\n------|--------\n![](https://github.com/LCAD-UFES/carmen_lcad/blob/master/src/road_mapper/data/i7705600_-338380.png?raw=true)|![](https://github.com/LCAD-UFES/carmen_lcad/blob/master/src/road_mapper/data/r7705600_-338380_map_1_6.png?raw=true)","metadata":{}},{"cell_type":"markdown","source":"\n\n## <div id=\"summary\">**<font color=\"#62909d\" size=\"5\">Tabela de Conteúdos</font>**</div>\n\n**<font size=\"2\"><a href=\"#chap1\">1. Instalar Pacotes</a></font>**\n**<br><font size=\"2\"><a href=\"#chap2\">2. Configurações Iniciais</a></font>**\n**<br><font size=\"2\"><a href=\"#chap3\">3. Tratamento de Dados</a></font>**\n**<br><font size=\"2\"><a href=\"#chap4\">4. Compilação e Treinamento da Rede</a></font>**\n**<br><font size=\"2\"><a href=\"#chap5\">5. Analisando os Resultados</a></font>**\n**<br><font size=\"2\"><a href=\"#chap6\">6. Realizando Testes</a></font>**","metadata":{}},{"cell_type":"markdown","source":"<div id=\"chap1\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:50px;text-align:center\">Instalar Pacotes</h1></div>\n","metadata":{}},{"cell_type":"code","source":"%pip install opencv-python\n%pip install tensorflow\n%pip install numpy\n%pip install tqdm\n%pip install scikit-image\n%pip install scikit-learn\n%pip install matplotlib\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:08:02.718463Z","iopub.execute_input":"2023-08-17T20:08:02.719321Z","iopub.status.idle":"2023-08-17T20:08:43.485973Z","shell.execute_reply.started":"2023-08-17T20:08:02.719275Z","shell.execute_reply":"2023-08-17T20:08:43.48497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"chap2\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:30px;text-align:center\">Configurações Iniciais</h1></div>\n","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\n\nimport numpy as np\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize","metadata":{"id":"I0NRq8jOY5bX","execution":{"iopub.status.busy":"2023-08-22T17:53:24.89878Z","iopub.execute_input":"2023-08-22T17:53:24.899146Z","iopub.status.idle":"2023-08-22T17:53:25.555075Z","shell.execute_reply.started":"2023-08-22T17:53:24.899115Z","shell.execute_reply":"2023-08-22T17:53:25.554059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE_X = 128 \nSIZE_Y = 128\n\nTRAIN_PATH = 'DATASET/treino/'\nTEST_PATH_HIGHWAY = 'DATASET/teste/highway/'\nTEST_PATH_UFES = 'DATASET/teste/ufes/'\n\nIMG_CHANNELS = 1\nNUM_CLASSES = 17  # Número de classes","metadata":{"id":"3MJ7xjSDZDJZ","execution":{"iopub.status.busy":"2023-08-22T17:53:25.933247Z","iopub.execute_input":"2023-08-22T17:53:25.933967Z","iopub.status.idle":"2023-08-22T17:53:25.940905Z","shell.execute_reply.started":"2023-08-22T17:53:25.933927Z","shell.execute_reply":"2023-08-22T17:53:25.939848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"chap3\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:50px;text-align:center\">Tratamento de Dados</h1></div>\n\nPule essa etapa se você já tiver seus dados prontos em um JSON.","metadata":{}},{"cell_type":"markdown","source":"**<font color=\"#62909d\" size=\"5\">Importando os arquivos</font>**\n","metadata":{}},{"cell_type":"code","source":"# Obter uma lista das subpastas\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids_hw = next(os.walk(TEST_PATH_HIGHWAY))[1]\ntest_ids_uf = next(os.walk(TEST_PATH_UFES))[1]","metadata":{"execution":{"iopub.status.busy":"2023-08-03T18:47:08.48592Z","iopub.execute_input":"2023-08-03T18:47:08.486809Z","iopub.status.idle":"2023-08-03T18:47:08.827352Z","shell.execute_reply.started":"2023-08-03T18:47:08.486752Z","shell.execute_reply":"2023-08-03T18:47:08.825847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.zeros((len(train_ids), SIZE_Y, SIZE_X, IMG_CHANNELS), dtype = np.uint8)\nY_train = np.zeros((len(train_ids), SIZE_Y, SIZE_X), dtype = np.uint8)\n\n\nX_test1 = np.zeros((len(test_ids_hw), SIZE_Y, SIZE_X, IMG_CHANNELS), dtype=np.uint8)\nY_test1= np.zeros((len(test_ids_hw), SIZE_Y, SIZE_X, 1), dtype = np.uint8)\n\n\nX_test2 = np.zeros((len(test_ids_uf), SIZE_Y, SIZE_X, IMG_CHANNELS), dtype=np.uint8)\nY_test2= np.zeros((len(test_ids_uf), SIZE_Y, SIZE_X, 1), dtype = np.uint8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CARREGA IMAGENS PARA ARRAY DE TREINO\n\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):  \n    \n    path = TRAIN_PATH + id_  \n    img = imread(path + '/images/i' + id_ + '.png', 0)[:, :, :IMG_CHANNELS]  \n    img = resize(img, (SIZE_Y, SIZE_X), mode='constant', preserve_range=True)  \n    X_train[n] = img \n    mask = np.zeros((SIZE_Y, SIZE_X, 1), dtype = np.uint8)  \n    \n    for mask_file in next(os.walk(path + '/masks/'))[2]:  \n        mask_ = imread(path + '/masks/' + mask_file, 0)\n        mask = resize(mask_, (SIZE_Y, SIZE_X), mode='constant', preserve_range=True)\n        \n    Y_train[n] = mask\nY_train = np.expand_dims(Y_train, axis = 3)    ","metadata":{"id":"e-qxgNa8ZQ_H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SALVAR ARRAYS DAS IMAGENS\n\nimport pickle\ntry:  \n    arquivo = open(\"bin/treinoX.bin\", \"wb\")\n    pickle.dump(X_train, arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treino.\")\n    \ntry:  \n    arquivo = open(\"bin/treinoY.bin\", \"wb\")\n    pickle.dump(Y_train, arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo teste.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  LOAD DOS ARRAYS SALVOS\n\nimport pickle\n\ntry:\n    arquivo = open(\"/kaggle/input/road-mapper-dataset/treinoX.bin\", \"rb\")\n    X_train = pickle.load(arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treinox.\")\n    \ntry:\n    arquivo = open(\"/kaggle/input/road-mapper-dataset/treinoY.bin\", \"rb\")\n    Y_train = pickle.load(arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treinoy.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-08T17:06:38.63182Z","iopub.execute_input":"2023-08-08T17:06:38.632206Z","iopub.status.idle":"2023-08-08T17:06:44.581422Z","shell.execute_reply.started":"2023-08-08T17:06:38.632171Z","shell.execute_reply":"2023-08-08T17:06:44.580377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dataset = X_train\nmask_dataset = Y_train","metadata":{"id":"JMVZCMFPZGPX","execution":{"iopub.status.busy":"2023-08-08T17:06:44.58333Z","iopub.execute_input":"2023-08-08T17:06:44.583692Z","iopub.status.idle":"2023-08-08T17:06:44.588232Z","shell.execute_reply.started":"2023-08-08T17:06:44.583648Z","shell.execute_reply":"2023-08-08T17:06:44.587034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**<font color=\"#62909d\" size=\"5\">Normalização e tratamento dos arrays</font>**\n","metadata":{}},{"cell_type":"code","source":"print(\"Image data shape is: \", image_dataset.shape)\nprint(\"Mask data shape is: \", mask_dataset.shape)\nprint(\"Max pixel value in image is: \", image_dataset.max())\nprint(\"Labels in the mask are : \", np.unique(mask_dataset))","metadata":{"id":"QzAouaVaZoVg","outputId":"bf942f6f-1ff5-448b-beaa-44f01c523110","execution":{"iopub.status.busy":"2023-08-08T17:06:44.589784Z","iopub.execute_input":"2023-08-08T17:06:44.590428Z","iopub.status.idle":"2023-08-08T17:06:49.637605Z","shell.execute_reply.started":"2023-08-08T17:06:44.590396Z","shell.execute_reply":"2023-08-08T17:06:49.636389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\nn, h, w = mask_dataset.shape  \nmask_dataset_reshaped = mask_dataset.reshape(-1,1)\nmask_dataset_reshaped_encoded = labelencoder.fit_transform(mask_dataset_reshaped)\nmask_dataset_encoded = mask_dataset_reshaped_encoded.reshape(n, h, w)\n\nnp.unique(mask_dataset_encoded)","metadata":{"id":"ibHIDZGfZkTh","outputId":"7a4e6ce5-7df7-49e0-e519-ab64f0ba1ec2","execution":{"iopub.status.busy":"2023-08-08T17:07:06.755763Z","iopub.execute_input":"2023-08-08T17:07:06.756247Z","iopub.status.idle":"2023-08-08T17:07:07.183881Z","shell.execute_reply.started":"2023-08-08T17:07:06.756208Z","shell.execute_reply":"2023-08-08T17:07:07.180911Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_dataset_encoded = np.expand_dims(mask_dataset_encoded, axis = 3)\nprint(mask_dataset_encoded.shape)","metadata":{"id":"QDQ_8v3FhENA","outputId":"af8a0fa2-0fac-43b5-ca97-5098f44d5e95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalizar images\nimage_dataset = image_dataset /255.  #Can also normalize or scale using MinMax scaler","metadata":{"id":"9SgFwOThZs_A","execution":{"iopub.status.busy":"2023-08-08T17:07:18.291313Z","iopub.execute_input":"2023-08-08T17:07:18.291693Z","iopub.status.idle":"2023-08-08T17:07:18.914975Z","shell.execute_reply.started":"2023-08-08T17:07:18.29166Z","shell.execute_reply":"2023-08-08T17:07:18.913911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dividir dados de treino e teste\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.2, random_state = 42)","metadata":{"id":"IMZPM7edZ4nN","execution":{"iopub.status.busy":"2023-08-08T17:07:20.420326Z","iopub.execute_input":"2023-08-08T17:07:20.420692Z","iopub.status.idle":"2023-08-08T17:07:21.211836Z","shell.execute_reply.started":"2023-08-08T17:07:20.420654Z","shell.execute_reply":"2023-08-08T17:07:21.210779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**<font color=\"#62909d\" size=\"5\">Salvar arquivo como CSV</font>**\n","metadata":{}},{"cell_type":"code","source":"import csv\nimport pandas as pd\n\ndef salvar_csv(X, Y, file_name):\n    # Criar um DataFrame com os arrays\n    data = {'X_input': X.tolist(), 'Y_output': Y.tolist()}\n    df = pd.DataFrame(data)\n    df.to_csv(file_name, index=False, mode=\"a\")","metadata":{"execution":{"iopub.status.busy":"2023-07-20T20:03:44.828398Z","iopub.execute_input":"2023-07-20T20:03:44.828811Z","iopub.status.idle":"2023-07-20T20:03:44.84685Z","shell.execute_reply.started":"2023-07-20T20:03:44.828778Z","shell.execute_reply":"2023-07-20T20:03:44.845644Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,8):\n    print(i)\n    salvar_csv(X_train[(i*5000):((i+1)*5000)], Y_train[(i*5000):((i+1)*5000)], 'train_data50.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-21T21:33:01.792638Z","iopub.execute_input":"2023-07-21T21:33:01.792991Z","iopub.status.idle":"2023-07-21T21:33:10.825085Z","shell.execute_reply.started":"2023-07-21T21:33:01.792963Z","shell.execute_reply":"2023-07-21T21:33:10.824096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in range(0,2):\n    print(j)\n    salvar_csv(X_test[(j*5000):((j+1)*5000)], Y_test[(j*5000):((j+1)*5000)], 'test_data50.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\ndisplay(FileLink('train_data.csv'))\ndisplay(FileLink('test_data.csv'))\n","metadata":{"id":"Yh2fI72laFn1","execution":{"iopub.status.busy":"2023-07-24T19:28:20.252922Z","iopub.execute_input":"2023-07-24T19:28:20.25618Z","iopub.status.idle":"2023-07-24T19:28:24.266924Z","shell.execute_reply.started":"2023-07-24T19:28:20.256117Z","shell.execute_reply":"2023-07-24T19:28:24.265881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"chap4\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:40px;text-align:center\">Compilação e Treinamento da Rede</h1></div>","metadata":{}},{"cell_type":"markdown","source":"**<font color=\"#62909d\" size=\"5\">Modelo 1 - Original U-NET</font>**","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\nfrom keras.optimizers import Adam\nfrom keras.layers import Activation, MaxPool2D, Concatenate","metadata":{"execution":{"iopub.status.busy":"2023-08-22T17:38:30.94292Z","iopub.execute_input":"2023-08-22T17:38:30.943249Z","iopub.status.idle":"2023-08-22T17:38:38.579028Z","shell.execute_reply.started":"2023-08-22T17:38:30.94322Z","shell.execute_reply":"2023-08-22T17:38:38.578062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construindo a UNET dividindo em blocos enconder e decoder\n\ndef conv_block(input, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n    x = BatchNormalization()(x)   #Not in the original network. \n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)  #Not in the original network\n    x = Activation(\"relu\")(x)\n\n    return x\n\n# Bloco Encoder: Bloco Conv seguindo por maxpooling\n\ndef encoder_block(input, num_filters):\n    x = conv_block(input, num_filters)\n    p = MaxPool2D((2, 2))(x)\n    return x, p   \n\n# Bloco Decoder\n# Pula features recebe de entrada os dados direto do encoder para a concatenação\n\ndef decoder_block(input, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\n# Construção da UNET\ndef build_unet(input_shape, n_classes):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024) #Bridge\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n    \n\n    if n_classes == 1:  #Binary\n      activation = 'sigmoid'\n    else:\n      activation = 'softmax'\n\n    outputs = Conv2D(NUM_CLASSES, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n    print(activation)\n\n    model = Model(inputs, outputs, name=\"U-Net\")\n    return model","metadata":{"id":"CNEIG7sKaR0D","execution":{"iopub.status.busy":"2023-08-22T17:53:10.860429Z","iopub.execute_input":"2023-08-22T17:53:10.861024Z","iopub.status.idle":"2023-08-22T17:53:10.874079Z","shell.execute_reply.started":"2023-08-22T17:53:10.860988Z","shell.execute_reply":"2023-08-22T17:53:10.872823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Criando uma função para um convolution block\ndef conv_block(inputs, num_filters):\n    x = tf.keras.layers.Conv2D(num_filters, (3, 3), activation=\"relu\", \n                               kernel_initializer=\"he_normal\", padding=\"same\")(inputs)\n    x = tf.keras.layers.Dropout(0.1)(x)\n    x = tf.keras.layers.Conv2D(num_filters, (3, 3), activation=\"relu\", \n                               kernel_initializer=\"he_normal\", padding=\"same\")(x)\n    return x\n\n# Criando a função para o expanding path\ndef upsample_block(inputs, conv_prev, num_filters):\n    up = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding=\"same\")(inputs)\n    concat = tf.keras.layers.concatenate([up, conv_prev])\n    conv = conv_block(concat, num_filters)\n    return conv\n","metadata":{"execution":{"iopub.status.busy":"2023-08-22T17:53:12.795841Z","iopub.execute_input":"2023-08-22T17:53:12.796206Z","iopub.status.idle":"2023-08-22T17:53:12.803592Z","shell.execute_reply.started":"2023-08-22T17:53:12.796178Z","shell.execute_reply":"2023-08-22T17:53:12.802607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Inputs\ninputs = tf.keras.layers.Input((SIZE_X, SIZE_Y, IMG_CHANNELS))\n\n# Normalização\ns = tf.keras.layers.Lambda(lambda x: x/255.0)(inputs) \n\n# Contraction path\nc1 = conv_block(s, 16)\np1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n\nc2 = conv_block(p1, 32)\np2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n\nc3 = conv_block(p2, 64)\np3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n\nc4 = conv_block(p3, 128)\np4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n\nc5 = conv_block(p4, 256)\n\n# Expansive path\nc6 = upsample_block(c5, c4, 128)\nc7 = upsample_block(c6, c3, 64)\nc8 = upsample_block(c7, c2, 32)\nc9 = upsample_block(c8, c1, 16)\n\n# Output layer\n\noutputs = tf.keras.layers.Conv2D(NUM_CLASSES, (1, 1), activation='softmax')(c9)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T17:53:37.470212Z","iopub.execute_input":"2023-08-22T17:53:37.470693Z","iopub.status.idle":"2023-08-22T17:53:40.557836Z","shell.execute_reply.started":"2023-08-22T17:53:37.470652Z","shell.execute_reply":"2023-08-22T17:53:40.556844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Model(inputs=[inputs], outputs=[outputs], name=\"U-Net\")\n\n# Compilação\nopt = tf.keras.optimizers.Adam(learning_rate=0.005)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\nmodel.summary()","metadata":{"id":"HcQp3wxCaTZw","outputId":"eaa198f6-cc50-4aa6-a635-bedff8c0e71e","execution":{"iopub.status.busy":"2023-08-22T17:53:40.561808Z","iopub.execute_input":"2023-08-22T17:53:40.562111Z","iopub.status.idle":"2023-08-22T17:53:40.676158Z","shell.execute_reply.started":"2023-08-22T17:53:40.562085Z","shell.execute_reply":"2023-08-22T17:53:40.675376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**<font color=\"#62909d\" size=\"5\">Modelo 2 - Squeeze U-NET</font>**","metadata":{}},{"cell_type":"code","source":"\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout\nfrom keras.layers import concatenate, Conv2DTranspose, BatchNormalization\nfrom keras import backend as K\n\n\n\ndef fire_module(x, fire_id, squeeze=16, expand=64):\n    f_name = \"fire{0}/{1}\"\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n\n    x = Conv2D(squeeze, (1, 1), activation='relu', padding='same', name=f_name.format(fire_id, \"squeeze1x1\"))(x)\n    x = BatchNormalization(axis=channel_axis)(x)\n\n    left = Conv2D(expand, (1, 1), activation='relu', padding='same', name=f_name.format(fire_id, \"expand1x1\"))(x)\n    right = Conv2D(expand, (3, 3), activation='relu', padding='same', name=f_name.format(fire_id, \"expand3x3\"))(x)\n    x = concatenate([left, right], axis=channel_axis, name=f_name.format(fire_id, \"concat\"))\n    return x\n\n\ndef SqueezeUNet(inputs, num_classes=None, deconv_ksize=3, dropout=0.5, activation='sigmoid'):\n    \"\"\"SqueezeUNet is a implementation based in SqueezeNetv1.1 and unet for semantic segmentation\n    :param inputs: input layer.\n    :param num_classes: number of classes.\n    :param deconv_ksize: (width and height) or integer of the 2D deconvolution window.\n    :param dropout: dropout rate\n    :param activation: type of activation at the top layer.\n    :returns: SqueezeUNet model\n    \"\"\"\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    if num_classes is None:\n        num_classes = K.int_shape(inputs)[channel_axis]\n\n    x01 = Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu', name='conv1')(inputs)\n    x02 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1', padding='same')(x01)\n\n    x03 = fire_module(x02, fire_id=2, squeeze=16, expand=64)\n    x04 = fire_module(x03, fire_id=3, squeeze=16, expand=64)\n    x05 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3', padding=\"same\")(x04)\n\n    x06 = fire_module(x05, fire_id=4, squeeze=32, expand=128)\n    x07 = fire_module(x06, fire_id=5, squeeze=32, expand=128)\n    x08 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5', padding=\"same\")(x07)\n\n    x09 = fire_module(x08, fire_id=6, squeeze=48, expand=192)\n    x10 = fire_module(x09, fire_id=7, squeeze=48, expand=192)\n    x11 = fire_module(x10, fire_id=8, squeeze=64, expand=256)\n    x12 = fire_module(x11, fire_id=9, squeeze=64, expand=256)\n\n    if dropout != 0.0:\n        x12 = Dropout(dropout)(x12)\n\n    up1 = concatenate([\n        Conv2DTranspose(192, deconv_ksize, strides=(1, 1), padding='same')(x12),\n        x10,\n    ], axis=channel_axis)\n    up1 = fire_module(up1, fire_id=10, squeeze=48, expand=192)\n\n    up2 = concatenate([\n        Conv2DTranspose(128, deconv_ksize, strides=(1, 1), padding='same')(up1),\n        x08,\n    ], axis=channel_axis)\n    up2 = fire_module(up2, fire_id=11, squeeze=32, expand=128)\n\n    up3 = concatenate([\n        Conv2DTranspose(64, deconv_ksize, strides=(2, 2), padding='same')(up2),\n        x05,\n    ], axis=channel_axis)\n    up3 = fire_module(up3, fire_id=12, squeeze=16, expand=64)\n\n    up4 = concatenate([\n        Conv2DTranspose(32, deconv_ksize, strides=(2, 2), padding='same')(up3),\n        x02,\n    ], axis=channel_axis)\n    up4 = fire_module(up4, fire_id=13, squeeze=16, expand=32)\n    up4 = UpSampling2D(size=(2, 2))(up4)\n\n    x = concatenate([up4, x01], axis=channel_axis)\n    x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(num_classes, (1, 1), activation=activation)(x)\n\n    return Model(inputs=inputs, outputs=x)\n   ","metadata":{"execution":{"iopub.status.busy":"2023-08-15T20:55:02.837711Z","iopub.execute_input":"2023-08-15T20:55:02.838162Z","iopub.status.idle":"2023-08-15T20:55:11.622656Z","shell.execute_reply.started":"2023-08-15T20:55:02.83811Z","shell.execute_reply":"2023-08-15T20:55:11.621382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import Input\n\ninputs = Input((SIZE_X, SIZE_Y, IMG_CHANNELS))\nmodel = SqueezeUNet(inputs, num_classes=NUM_CLASSES, deconv_ksize=3)\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.005)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-15T20:55:30.110538Z","iopub.execute_input":"2023-08-15T20:55:30.111442Z","iopub.status.idle":"2023-08-15T20:55:36.004838Z","shell.execute_reply.started":"2023-08-15T20:55:30.1114Z","shell.execute_reply":"2023-08-15T20:55:36.003866Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**<font color=\"#62909d\" size=\"5\">Batch Generator</font>**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nimport json\n\ndef batch_generator(Train_df,batch_size,\n                    steps):\n    idx=1\n    while True: \n        yield load_data(Train_df,idx-1,batch_size)## Yields data\n        if idx<=steps:\n            idx+=1\n        else:\n            idx=1\n            \ndef load_data(Train_df,idx,\n              batch_size):\n    n_classes = 17\n\n    df = pd.read_csv(\n                  Train_df, skiprows=idx*batch_size,\n                  nrows=batch_size)\n    \n    x = [] \n    y = []\n    \n    for i in range(0, batch_size):\n        x.append(json.loads(df.iloc[i,0]))\n        y.append(json.loads(df.iloc[i,1]))\n    \n    y = np.asarray(y)\n    train_masks_cat = to_categorical(y, num_classes=n_classes)\n    y_train_cat = train_masks_cat.reshape((y.shape[0], y.shape[1], y.shape[2], n_classes))\n    \n    return (np.asarray(x), y_train_cat)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T17:55:29.359466Z","iopub.execute_input":"2023-08-22T17:55:29.360428Z","iopub.status.idle":"2023-08-22T17:55:29.36983Z","shell.execute_reply.started":"2023-08-22T17:55:29.360395Z","shell.execute_reply":"2023-08-22T17:55:29.368876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nfrom keras.models import Sequential \nfrom keras.layers import Dense, Activation\nbatch_size = 8 \nnb_epoch = 3\n\n# Objetos gerados para treino e validação\nsteps_per_epoch=np.ceil(2000/batch_size)\nvalidation_steps=np.ceil(400/batch_size)\n\nmy_training_batch_generator = batch_generator('/kaggle/input/road-mapper-dataset-csv/train_data.csv', batch_size,steps_per_epoch)\nmy_validation_batch_generator = batch_generator('/kaggle/input/road-mapper-dataset-csv/test_data.csv', batch_size,validation_steps)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-22T17:56:40.754715Z","iopub.execute_input":"2023-08-22T17:56:40.755137Z","iopub.status.idle":"2023-08-22T17:56:40.765303Z","shell.execute_reply.started":"2023-08-22T17:56:40.755082Z","shell.execute_reply":"2023-08-22T17:56:40.764147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimport pandas as pd\n\nhistory = model.fit(my_training_batch_generator,\n                    epochs=nb_epoch,\n                    steps_per_epoch=steps_per_epoch,\n                    verbose=1, \n                    validation_data=my_validation_batch_generator,\n                    validation_steps=validation_steps,\n                    shuffle=True,\n                    use_multiprocessing=True)\n","metadata":{"id":"LmcYufmuaeUz","outputId":"1e547c95-01a1-4ec2-a5da-b321bc959826","execution":{"iopub.status.busy":"2023-08-22T17:56:43.661322Z","iopub.execute_input":"2023-08-22T17:56:43.661773Z","iopub.status.idle":"2023-08-22T18:44:07.299426Z","shell.execute_reply.started":"2023-08-22T17:56:43.661734Z","shell.execute_reply":"2023-08-22T18:44:07.192018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salvando o modelo\nmodel.save('multiclass_road_mapper')\n","metadata":{"id":"KQ_NuTmlafmh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salvando os resultados\nimport pickle\ntry:  \n    arquivo = open(\"results.bin\", \"wb\")\n    pickle.dump(history, arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo results.\")\n   ","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:53:55.755564Z","iopub.execute_input":"2023-08-22T18:53:55.755912Z","iopub.status.idle":"2023-08-22T18:54:04.387558Z","shell.execute_reply.started":"2023-08-22T18:53:55.755884Z","shell.execute_reply":"2023-08-22T18:54:04.371993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salvando os resultados\nimport pickle\ntry:  \n    arquivo = open(\"results.json\", \"w\")\n    json.dump(history, arquivo, indent=4)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo results json.\")\n   ","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:53:27.475559Z","iopub.execute_input":"2023-08-22T18:53:27.475921Z","iopub.status.idle":"2023-08-22T18:53:27.500548Z","shell.execute_reply.started":"2023-08-22T18:53:27.475891Z","shell.execute_reply":"2023-08-22T18:53:27.489856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_file('/kaggle/working', 'out')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"chap5\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:40px;text-align:center\">Analisando os Resultados</h1></div>","metadata":{}},{"cell_type":"code","source":"\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\n\nplt.plot(epochs, acc, 'y', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"id":"iVibZ6c1ao7P","outputId":"c9fb159a-53cd-456a-aff2-b0af62640283","execution":{"iopub.status.busy":"2023-08-22T18:57:46.636062Z","iopub.execute_input":"2023-08-22T18:57:46.64102Z","iopub.status.idle":"2023-08-22T18:57:50.711038Z","shell.execute_reply.started":"2023-08-22T18:57:46.640982Z","shell.execute_reply":"2023-08-22T18:57:50.710079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load do modelo salvo\nfrom keras.models import load_model\nmodel = load_model(\"/content/drive/MyDrive/Colab Notebooks/saved_models/tutorial119_sandstone_50epochs.hdf5\", compile=False)","metadata":{"id":"RO7ACKoBapui"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"chap6\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:40px;text-align:center\">Realizando testes (Predict)</h1></div>","metadata":{}},{"cell_type":"code","source":"y_pred=model.predict(X_test)","metadata":{"id":"UNuftNH18ZoY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.shape","metadata":{"id":"b_SF6IU38cxw","outputId":"b1a4ac40-a3e9-40e7-95d7-b249ed13f6c6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_argmax=np.argmax(y_pred, axis=3)\ny_pred_argmax.shape","metadata":{"id":"drpgFz-SjPq3","outputId":"6934927b-6610-4784-b8dd-f75c7c320a78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using built in keras function\nfrom keras.metrics import MeanIoU\nn_classes = 4\nIOU_keras = MeanIoU(num_classes=n_classes)  \nIOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\nprint(\"Mean IoU =\", IOU_keras.result().numpy())","metadata":{"id":"5panJLTGawJx","outputId":"d195ca02-d42d-4388-a587-4ce8d7a7fcb7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To calculate I0U for each class...\nvalues = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\nprint(values)\nclass1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\nclass2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\nclass3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\nclass4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n\nprint(\"IoU for class1 is: \", class1_IoU)\nprint(\"IoU for class2 is: \", class2_IoU)\nprint(\"IoU for class3 is: \", class3_IoU)\nprint(\"IoU for class4 is: \", class4_IoU)\n\n","metadata":{"id":"hgHHa8q9axAx","outputId":"de3de859-7ca6-4f81-8d2d-a97501f6f3a1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict on a few images\n#model = get_model()\n#model.load_weights('???.hdf5')  \nimport random\ntest_img_number = random.randint(0, len(X_test)-1)\ntest_img = X_test[test_img_number]\nground_truth=y_test[test_img_number]\ntest_img_norm=test_img[:,:,0][:,:,None]\ntest_img_input=np.expand_dims(test_img_norm, 0)\nprediction = (model.predict(test_img_input))\npredicted_img=np.argmax(prediction, axis=3)[0,:,:]\n\n\nplt.figure(figsize=(12, 8))\nplt.subplot(231)\nplt.title('Testing Image')\nplt.imshow(test_img[:,:,0], cmap='gray')\nplt.subplot(232)\nplt.title('Testing Label')\nplt.imshow(ground_truth[:,:,0], cmap='jet')\nplt.subplot(233)\nplt.title('Prediction on test image')\nplt.imshow(predicted_img, cmap='jet')\nplt.show()","metadata":{"id":"zW-IdHfAa2f6","outputId":"68a6eb40-1f74-4f90-b489-6375a473151f"},"execution_count":null,"outputs":[]}]}