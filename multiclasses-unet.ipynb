{"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNh0U+v2EtxiJ6GesFrR7ku","collapsed_sections":[],"include_colab_link":true,"mount_file_id":"1RvuTk-Scq7viDQTc1Y2kDMNsD1xHXFyK","name":"tutorial119_multiclass_semantic_segmentation.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ludmiladias/multiclasses-unet?scriptVersionId=140214419\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div id=\"title\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:50px;text-align:center\">U-Net Multiclasses Training</h1></div>\n\nProjeto desenvolvido usando a rede de segmentação U-NET, biblioteca Keras e Tensorflow.\nO Road Mapper DNN tem como objetivo gerar mapas de estrada com segmentação das faixas de sinalização utilizada pelos veículos, tendo como entrada mapas de remissão gerados pelo LIDAR - sensor laser que faz parte do sistema de carros autônomos como o ASTRO da Lume Robotics.\n","metadata":{"id":"SscH4lze36iJ"}},{"cell_type":"markdown","source":"Input | Output\n------|--------\n![](https://github.com/LCAD-UFES/carmen_lcad/blob/master/src/road_mapper/data/i7705600_-338380.png?raw=true)|![](https://github.com/LCAD-UFES/carmen_lcad/blob/master/src/road_mapper/data/r7705600_-338380_map_1_6.png?raw=true)","metadata":{}},{"cell_type":"markdown","source":"\n\n## <div id=\"summary\">**<font color=\"#62909d\" size=\"5\">Tabela de Conteúdos</font>**</div>\n\n**<font size=\"2\"><a href=\"#chap1\">1. Instalar Pacotes</a></font>**\n**<br><font size=\"2\"><a href=\"#chap2\">2. Configurações Iniciais</a></font>**\n**<br><font size=\"2\"><a href=\"#chap3\">3. Tratamento de Dados</a></font>**\n**<br><font size=\"2\"><a href=\"#chap4\">4. Compilação e Treinamento da Rede</a></font>**\n**<br><font size=\"2\"><a href=\"#chap5\">5. Analisando os Resultados</a></font>**\n**<br><font size=\"2\"><a href=\"#chap6\">6. Realizando Testes</a></font>**","metadata":{}},{"cell_type":"markdown","source":"<div id=\"chap1\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:50px;text-align:center\">Instalar Pacotes</h1></div>\n","metadata":{}},{"cell_type":"code","source":"%pip install opencv-python\n%pip install tensorflow\n%pip install numpy\n%pip install tqdm\n%pip install scikit-image\n%pip install scikit-learn\n%pip install matplotlib\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"chap2\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:30px;text-align:center\">Configurações Iniciais</h1></div>\n","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\n\nimport numpy as np\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize","metadata":{"id":"I0NRq8jOY5bX","execution":{"iopub.status.busy":"2023-08-15T20:54:14.024591Z","iopub.execute_input":"2023-08-15T20:54:14.024952Z","iopub.status.idle":"2023-08-15T20:54:16.009319Z","shell.execute_reply.started":"2023-08-15T20:54:14.024917Z","shell.execute_reply":"2023-08-15T20:54:16.008075Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"SIZE_X = 128 \nSIZE_Y = 128\n\nTRAIN_PATH = 'DATASET/treino/'\nTEST_PATH_HIGHWAY = 'DATASET/teste/highway/'\nTEST_PATH_UFES = 'DATASET/teste/ufes/'\n\nIMG_CHANNELS = 1\nNUM_CLASSES = 17  # Número de classes","metadata":{"id":"3MJ7xjSDZDJZ","execution":{"iopub.status.busy":"2023-08-16T16:04:34.818326Z","iopub.execute_input":"2023-08-16T16:04:34.81887Z","iopub.status.idle":"2023-08-16T16:04:34.824988Z","shell.execute_reply.started":"2023-08-16T16:04:34.818829Z","shell.execute_reply":"2023-08-16T16:04:34.823792Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"chap3\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:50px;text-align:center\">Tratamento de Dados</h1></div>\n\nPule essa etapa se você já tiver seus dados prontos em um JSON.","metadata":{}},{"cell_type":"markdown","source":"**<font color=\"#62909d\" size=\"5\">Configurações Iniciais</font>**\n","metadata":{}},{"cell_type":"code","source":"# Obter uma lista das subpastas\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids_hw = next(os.walk(TEST_PATH_HIGHWAY))[1]\ntest_ids_uf = next(os.walk(TEST_PATH_UFES))[1]","metadata":{"execution":{"iopub.status.busy":"2023-08-03T18:47:08.48592Z","iopub.execute_input":"2023-08-03T18:47:08.486809Z","iopub.status.idle":"2023-08-03T18:47:08.827352Z","shell.execute_reply.started":"2023-08-03T18:47:08.486752Z","shell.execute_reply":"2023-08-03T18:47:08.825847Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get list of all subfolders\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m test_ids_hw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(os\u001b[38;5;241m.\u001b[39mwalk(TEST_PATH_HIGHWAY))[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m test_ids_uf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(os\u001b[38;5;241m.\u001b[39mwalk(TEST_PATH_UFES))[\u001b[38;5;241m1\u001b[39m]\n","\u001b[0;31mStopIteration\u001b[0m: "],"ename":"StopIteration","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"X_train = np.zeros((len(train_ids), SIZE_Y, SIZE_X, IMG_CHANNELS), dtype = np.uint8)\nY_train = np.zeros((len(train_ids), SIZE_Y, SIZE_X), dtype = np.uint8)\n\n\nX_test1 = np.zeros((len(test_ids_hw), SIZE_Y, SIZE_X, IMG_CHANNELS), dtype=np.uint8)\nY_test1= np.zeros((len(test_ids_hw), SIZE_Y, SIZE_X, 1), dtype = np.uint8)\n\n\nX_test2 = np.zeros((len(test_ids_uf), SIZE_Y, SIZE_X, IMG_CHANNELS), dtype=np.uint8)\nY_test2= np.zeros((len(test_ids_uf), SIZE_Y, SIZE_X, 1), dtype = np.uint8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CARREGA IMAGENS PARA ARRAY DE TREINO\n\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):  \n    \n    path = TRAIN_PATH + id_  \n    img = imread(path + '/images/i' + id_ + '.png', 0)[:, :, :IMG_CHANNELS]  \n    img = resize(img, (SIZE_Y, SIZE_X), mode='constant', preserve_range=True)  \n    X_train[n] = img \n    mask = np.zeros((SIZE_Y, SIZE_X, 1), dtype = np.uint8)  \n    \n    for mask_file in next(os.walk(path + '/masks/'))[2]:  \n        mask_ = imread(path + '/masks/' + mask_file, 0)\n        mask = resize(mask_, (SIZE_Y, SIZE_X), mode='constant', preserve_range=True)\n        \n    Y_train[n] = mask\nY_train = np.expand_dims(Y_train, axis = 3)    ","metadata":{"id":"e-qxgNa8ZQ_H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SALVAR ARRAYS DAS IMAGENS\n\nimport pickle\ntry:  \n    arquivo = open(\"bin/treinoX.bin\", \"wb\")\n    pickle.dump(X_train, arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treino.\")\n    \ntry:  \n    arquivo = open(\"bin/treinoY.bin\", \"wb\")\n    pickle.dump(Y_train, arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo teste.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  LOAD DOS ARRAYS SALVOS\n\nimport pickle\n\ntry:\n    arquivo = open(\"/kaggle/input/road-mapper-dataset/treinoX.bin\", \"rb\")\n    X_train = pickle.load(arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treinox.\")\n    \ntry:\n    arquivo = open(\"/kaggle/input/road-mapper-dataset/treinoY.bin\", \"rb\")\n    Y_train = pickle.load(arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treinoy.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-08T17:06:38.63182Z","iopub.execute_input":"2023-08-08T17:06:38.632206Z","iopub.status.idle":"2023-08-08T17:06:44.581422Z","shell.execute_reply.started":"2023-08-08T17:06:38.632171Z","shell.execute_reply":"2023-08-08T17:06:44.580377Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"image_dataset = X_train\nmask_dataset = Y_train","metadata":{"id":"JMVZCMFPZGPX","execution":{"iopub.status.busy":"2023-08-08T17:06:44.58333Z","iopub.execute_input":"2023-08-08T17:06:44.583692Z","iopub.status.idle":"2023-08-08T17:06:44.588232Z","shell.execute_reply.started":"2023-08-08T17:06:44.583648Z","shell.execute_reply":"2023-08-08T17:06:44.587034Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**<font color=\"#62909d\" size=\"5\">Normalização e tratamento dos arrays</font>**\n","metadata":{}},{"cell_type":"code","source":"print(\"Image data shape is: \", image_dataset.shape)\nprint(\"Mask data shape is: \", mask_dataset.shape)\nprint(\"Max pixel value in image is: \", image_dataset.max())\nprint(\"Labels in the mask are : \", np.unique(mask_dataset))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzAouaVaZoVg","outputId":"bf942f6f-1ff5-448b-beaa-44f01c523110","execution":{"iopub.status.busy":"2023-08-08T17:06:44.589784Z","iopub.execute_input":"2023-08-08T17:06:44.590428Z","iopub.status.idle":"2023-08-08T17:06:49.637605Z","shell.execute_reply.started":"2023-08-08T17:06:44.590396Z","shell.execute_reply":"2023-08-08T17:06:49.636389Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Image data shape is:  (15000, 128, 128, 1)\nMask data shape is:  (15000, 128, 128, 1)\nMax pixel value in image is:  254\nLabels in the mask are :  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\nn, h, w = mask_dataset.shape  \nmask_dataset_reshaped = mask_dataset.reshape(-1,1)\nmask_dataset_reshaped_encoded = labelencoder.fit_transform(mask_dataset_reshaped)\nmask_dataset_encoded = mask_dataset_reshaped_encoded.reshape(n, h, w)\n\nnp.unique(mask_dataset_encoded)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ibHIDZGfZkTh","outputId":"7a4e6ce5-7df7-49e0-e519-ab64f0ba1ec2","execution":{"iopub.status.busy":"2023-08-08T17:07:06.755763Z","iopub.execute_input":"2023-08-08T17:07:06.756247Z","iopub.status.idle":"2023-08-08T17:07:07.183881Z","shell.execute_reply.started":"2023-08-08T17:07:06.756208Z","shell.execute_reply":"2023-08-08T17:07:07.180911Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      3\u001b[0m labelencoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m----> 4\u001b[0m n, h, w \u001b[38;5;241m=\u001b[39m mask_dataset\u001b[38;5;241m.\u001b[39mshape  \n\u001b[1;32m      5\u001b[0m mask_dataset_reshaped \u001b[38;5;241m=\u001b[39m mask_dataset\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m mask_dataset_reshaped_encoded \u001b[38;5;241m=\u001b[39m labelencoder\u001b[38;5;241m.\u001b[39mfit_transform(mask_dataset_reshaped)\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"],"ename":"ValueError","evalue":"too many values to unpack (expected 3)","output_type":"error"}]},{"cell_type":"code","source":"mask_dataset_encoded = np.expand_dims(mask_dataset_encoded, axis = 3)\nprint(mask_dataset_encoded.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDQ_8v3FhENA","outputId":"af8a0fa2-0fac-43b5-ca97-5098f44d5e95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalizar images\nimage_dataset = image_dataset /255.  #Can also normalize or scale using MinMax scaler","metadata":{"id":"9SgFwOThZs_A","execution":{"iopub.status.busy":"2023-08-08T17:07:18.291313Z","iopub.execute_input":"2023-08-08T17:07:18.291693Z","iopub.status.idle":"2023-08-08T17:07:18.914975Z","shell.execute_reply.started":"2023-08-08T17:07:18.29166Z","shell.execute_reply":"2023-08-08T17:07:18.913911Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Dividir dados de treino e teste\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.2, random_state = 42)","metadata":{"id":"IMZPM7edZ4nN","execution":{"iopub.status.busy":"2023-08-08T17:07:20.420326Z","iopub.execute_input":"2023-08-08T17:07:20.420692Z","iopub.status.idle":"2023-08-08T17:07:21.211836Z","shell.execute_reply.started":"2023-08-08T17:07:20.420654Z","shell.execute_reply":"2023-08-08T17:07:21.210779Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# SALVAR ARRAYS DAS IMAGENS\n\nimport pickle\ntry:  \n    arquivo = open(\"bin/testeX_.bin\", \"wb\")\n    pickle.dump(X_test, arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treino.\")\n    \n# try:  \n#     arquivo = open(\"bin/testeY_.bin\", \"wb\")\n#     pickle.dump(y_test, arquivo)\n#     arquivo.close()\n# except:\n#     print(\"Problemas com o arquivo teste.\")\n    \ntry:  \n    arquivo = open(\"bin/treinoX_.bin\", \"wb\")\n    pickle.dump(X_train, arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treino.\")\n    \n# try:  \n#     arquivo = open(\"bin/treinoY_.bin\", \"wb\")\n#     pickle.dump(y_train, arquivo)\n#     arquivo.close()\n# except:\n#     print(\"Problemas com o arquivo teste.\")","metadata":{"execution":{"iopub.status.busy":"2023-07-20T20:03:44.828398Z","iopub.execute_input":"2023-07-20T20:03:44.828811Z","iopub.status.idle":"2023-07-20T20:03:44.84685Z","shell.execute_reply.started":"2023-07-20T20:03:44.828778Z","shell.execute_reply":"2023-07-20T20:03:44.845644Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Problemas com o arquivo treino.\nProblemas com o arquivo treino.\n","output_type":"stream"}]},{"cell_type":"code","source":"#  LOAD DOS ARRAYS SALVOS\n\nimport pickle\n\ntry:\n    arquivo = open(\"/kaggle/input/road-mapper-dataset/testeX_.bin\", \"rb\")\n    X_test = pickle.load(arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treinox.\")\n    \n# try:\n#     arquivo = open(\"/kaggle/input/road-mapper-dataset/testeY_.bin\", \"rb\")\n#     y_test = pickle.load(arquivo)\n#     arquivo.close()\n# except:\n#     print(\"Problemas com o arquivo treinoy.\")\ntry:\n    arquivo = open(\"/kaggle/input/road-mapper-dataset/treinoX_.bin\", \"rb\")\n    X_train = pickle.load(arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treinox.\")\n    \n# try:\n#     arquivo = open(\"/kaggle/input/road-mapper-dataset/treinoY_.bin\", \"rb\")\n#     y_train = pickle.load(arquivo)\n#     arquivo.close()\n# except:\n#     print(\"Problemas com o arquivo treinoy.\")","metadata":{"execution":{"iopub.status.busy":"2023-07-21T21:33:01.792638Z","iopub.execute_input":"2023-07-21T21:33:01.792991Z","iopub.status.idle":"2023-07-21T21:33:10.825085Z","shell.execute_reply.started":"2023-07-21T21:33:01.792963Z","shell.execute_reply":"2023-07-21T21:33:10.824096Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\ntrain_masks_cat = to_categorical(y_train, num_classes=NUM_CLASSES)\ny_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], NUM_CLASSES))\n\ntest_masks_cat = to_categorical(y_test, num_classes=NUM_CLASSES)\ny_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], NUM_CLASSES))\n","metadata":{"id":"Yh2fI72laFn1","execution":{"iopub.status.busy":"2023-07-24T19:28:20.252922Z","iopub.execute_input":"2023-07-24T19:28:20.25618Z","iopub.status.idle":"2023-07-24T19:28:24.266924Z","shell.execute_reply.started":"2023-07-24T19:28:20.256117Z","shell.execute_reply":"2023-07-24T19:28:24.265881Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# SALVAR ARRAYS DAS IMAGENS\n\nimport pickle\ntry:  \n    arquivo = open(\"y_train_cat.bin\", \"wb\")\n    pickle.dump(y_train_cat, arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treino.\")\n\ntry:  \n    arquivo = open(\"y_test_cat.bin\", \"wb\")\n    pickle.dump(y_test_cat, arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo teste.\")\n    \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\ntry:\n    arquivo = open(\"/kaggle/input/road-mapper-dataset/y_train_cat.bin\", \"rb\")\n    y_train_cat = pickle.load(arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treinox.\")\n    \ntry:\n    arquivo = open(\"/kaggle/input/road-mapper-dataset/y_test_cat.bin\", \"rb\")\n    y_test_cat = pickle.load(arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo treinoy.\")","metadata":{"execution":{"iopub.status.busy":"2023-07-21T21:33:41.662123Z","iopub.execute_input":"2023-07-21T21:33:41.662511Z","iopub.status.idle":"2023-07-21T21:34:48.539816Z","shell.execute_reply.started":"2023-07-21T21:33:41.66248Z","shell.execute_reply":"2023-07-21T21:34:48.538463Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(y_train_cat.shape)\nprint(y_test_cat.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDMoprb5hrvY","outputId":"07ba7bf8-bdad-4648-9b3e-d337b3c6f95c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SALVAR COMO ARQUIVO CSV (verificar tempo de execução...)\n\nimport csv\nimport pandas as pd\n\n# Criar um DataFrame com os arrays\ndata = {'X input': X_train.tolist(), 'Y output': y_train_cat.tolist()}\ndf = pd.DataFrame(data)\ndf.to_csv('train_data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:18:39.908096Z","iopub.execute_input":"2023-08-02T20:18:39.908478Z","iopub.status.idle":"2023-08-02T20:18:54.619636Z","shell.execute_reply.started":"2023-08-02T20:18:39.908447Z","shell.execute_reply":"2023-08-02T20:18:54.618273Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting mmap_ninja\n  Downloading mmap_ninja-0.6.5-py3-none-any.whl (12 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmap_ninja) (1.23.5)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from mmap_ninja) (4.65.0)\nInstalling collected packages: mmap_ninja\nSuccessfully installed mmap_ninja-0.6.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div id=\"chap4\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:40px;text-align:center\">Compilação e Treinamento da Rede</h1></div>","metadata":{}},{"cell_type":"markdown","source":"**<font color=\"#62909d\" size=\"5\">Modelo 1 - Original U-NET</font>**","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\nfrom keras.optimizers import Adam\nfrom keras.layers import Activation, MaxPool2D, Concatenate","metadata":{"execution":{"iopub.status.busy":"2023-08-16T16:04:22.533128Z","iopub.execute_input":"2023-08-16T16:04:22.533485Z","iopub.status.idle":"2023-08-16T16:04:22.539012Z","shell.execute_reply.started":"2023-08-16T16:04:22.533455Z","shell.execute_reply":"2023-08-16T16:04:22.537975Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Construindo a UNET dividindo em blocos enconder e decoder\n\ndef conv_block(input, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n    x = BatchNormalization()(x)   #Not in the original network. \n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)  #Not in the original network\n    x = Activation(\"relu\")(x)\n\n    return x\n\n# Bloco Encoder: Bloco Conv seguindo por maxpooling\n\ndef encoder_block(input, num_filters):\n    x = conv_block(input, num_filters)\n    p = MaxPool2D((2, 2))(x)\n    return x, p   \n\n# Bloco Decoder\n# Pula features recebe de entrada os dados direto do encoder para a concatenação\n\ndef decoder_block(input, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\n# Construção da UNET\ndef build_unet(input_shape, n_classes):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024) #Bridge\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n    \n\n    if n_classes == 1:  #Binary\n      activation = 'sigmoid'\n    else:\n      activation = 'softmax'\n\n    outputs = Conv2D(NUM_CLASSES, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n    print(activation)\n\n    model = Model(inputs, outputs, name=\"U-Net\")\n    return model","metadata":{"id":"CNEIG7sKaR0D","execution":{"iopub.status.busy":"2023-08-16T16:04:23.921484Z","iopub.execute_input":"2023-08-16T16:04:23.921844Z","iopub.status.idle":"2023-08-16T16:04:23.935406Z","shell.execute_reply.started":"2023-08-16T16:04:23.921812Z","shell.execute_reply":"2023-08-16T16:04:23.934022Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Criando uma função para um convolution block\ndef conv_block(inputs, num_filters):\n    x = tf.keras.layers.Conv2D(num_filters, (3, 3), activation=\"relu\", \n                               kernel_initializer=\"he_normal\", padding=\"same\")(inputs)\n    x = tf.keras.layers.Dropout(0.1)(x)\n    x = tf.keras.layers.Conv2D(num_filters, (3, 3), activation=\"relu\", \n                               kernel_initializer=\"he_normal\", padding=\"same\")(x)\n    return x\n\n# Criando a função para o expanding path\ndef upsample_block(inputs, conv_prev, num_filters):\n    up = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding=\"same\")(inputs)\n    concat = tf.keras.layers.concatenate([up, conv_prev])\n    conv = conv_block(concat, num_filters)\n    return conv\n","metadata":{"execution":{"iopub.status.busy":"2023-08-16T16:04:26.319148Z","iopub.execute_input":"2023-08-16T16:04:26.319542Z","iopub.status.idle":"2023-08-16T16:04:26.328216Z","shell.execute_reply.started":"2023-08-16T16:04:26.319509Z","shell.execute_reply":"2023-08-16T16:04:26.327013Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Inputs\ninputs = tf.keras.layers.Input((SIZE_X, SIZE_Y, IMG_CHANNELS))\n\n# Normalização\ns = tf.keras.layers.Lambda(lambda x: x/255.0)(inputs) \n\n# Contraction path\nc1 = conv_block(s, 16)\np1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n\nc2 = conv_block(p1, 32)\np2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n\nc3 = conv_block(p2, 64)\np3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n\nc4 = conv_block(p3, 128)\np4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n\nc5 = conv_block(p4, 256)\n\n# Expansive path\nc6 = upsample_block(c5, c4, 128)\nc7 = upsample_block(c6, c3, 64)\nc8 = upsample_block(c7, c2, 32)\nc9 = upsample_block(c8, c1, 16)\n\n# Output layer\n\noutputs = tf.keras.layers.Conv2D(NUM_CLASSES, (1, 1), activation='softmax')(c9)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T16:04:46.14745Z","iopub.execute_input":"2023-08-16T16:04:46.147808Z","iopub.status.idle":"2023-08-16T16:04:51.77369Z","shell.execute_reply.started":"2023-08-16T16:04:46.147777Z","shell.execute_reply":"2023-08-16T16:04:51.772623Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Model(inputs=[inputs], outputs=[outputs], name=\"U-Net\")\n\n# Compilação\nopt = tf.keras.optimizers.Adam(learning_rate=0.005)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\nmodel.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcQp3wxCaTZw","outputId":"eaa198f6-cc50-4aa6-a635-bedff8c0e71e","execution":{"iopub.status.busy":"2023-08-16T16:04:51.775917Z","iopub.execute_input":"2023-08-16T16:04:51.776274Z","iopub.status.idle":"2023-08-16T16:04:51.885902Z","shell.execute_reply.started":"2023-08-16T16:04:51.77624Z","shell.execute_reply":"2023-08-16T16:04:51.885119Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"U-Net\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n lambda (Lambda)                (None, 128, 128, 1)  0           ['input_1[0][0]']                \n                                                                                                  \n conv2d (Conv2D)                (None, 128, 128, 16  160         ['lambda[0][0]']                 \n                                )                                                                 \n                                                                                                  \n dropout (Dropout)              (None, 128, 128, 16  0           ['conv2d[0][0]']                 \n                                )                                                                 \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 128, 128, 16  2320        ['dropout[0][0]']                \n                                )                                                                 \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 64, 64, 16)   0           ['conv2d_1[0][0]']               \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 64, 64, 32)   4640        ['max_pooling2d[0][0]']          \n                                                                                                  \n dropout_1 (Dropout)            (None, 64, 64, 32)   0           ['conv2d_2[0][0]']               \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 64, 64, 32)   9248        ['dropout_1[0][0]']              \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)  0           ['conv2d_3[0][0]']               \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 32, 32, 64)   18496       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n dropout_2 (Dropout)            (None, 32, 32, 64)   0           ['conv2d_4[0][0]']               \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 32, 32, 64)   36928       ['dropout_2[0][0]']              \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)  0           ['conv2d_5[0][0]']               \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 16, 16, 128)  73856       ['max_pooling2d_2[0][0]']        \n                                                                                                  \n dropout_3 (Dropout)            (None, 16, 16, 128)  0           ['conv2d_6[0][0]']               \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 16, 16, 128)  147584      ['dropout_3[0][0]']              \n                                                                                                  \n max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)   0           ['conv2d_7[0][0]']               \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 8, 8, 256)    295168      ['max_pooling2d_3[0][0]']        \n                                                                                                  \n dropout_4 (Dropout)            (None, 8, 8, 256)    0           ['conv2d_8[0][0]']               \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 8, 8, 256)    590080      ['dropout_4[0][0]']              \n                                                                                                  \n conv2d_transpose (Conv2DTransp  (None, 16, 16, 128)  131200     ['conv2d_9[0][0]']               \n ose)                                                                                             \n                                                                                                  \n concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_transpose[0][0]',       \n                                                                  'conv2d_7[0][0]']               \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 16, 16, 128)  295040      ['concatenate[0][0]']            \n                                                                                                  \n dropout_5 (Dropout)            (None, 16, 16, 128)  0           ['conv2d_10[0][0]']              \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 16, 16, 128)  147584      ['dropout_5[0][0]']              \n                                                                                                  \n conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 64)  32832       ['conv2d_11[0][0]']              \n spose)                                                                                           \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_1[0][0]',     \n                                                                  'conv2d_5[0][0]']               \n                                                                                                  \n conv2d_12 (Conv2D)             (None, 32, 32, 64)   73792       ['concatenate_1[0][0]']          \n                                                                                                  \n dropout_6 (Dropout)            (None, 32, 32, 64)   0           ['conv2d_12[0][0]']              \n                                                                                                  \n conv2d_13 (Conv2D)             (None, 32, 32, 64)   36928       ['dropout_6[0][0]']              \n                                                                                                  \n conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 32)  8224        ['conv2d_13[0][0]']              \n spose)                                                                                           \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 64, 64, 64)   0           ['conv2d_transpose_2[0][0]',     \n                                                                  'conv2d_3[0][0]']               \n                                                                                                  \n conv2d_14 (Conv2D)             (None, 64, 64, 32)   18464       ['concatenate_2[0][0]']          \n                                                                                                  \n dropout_7 (Dropout)            (None, 64, 64, 32)   0           ['conv2d_14[0][0]']              \n                                                                                                  \n conv2d_15 (Conv2D)             (None, 64, 64, 32)   9248        ['dropout_7[0][0]']              \n                                                                                                  \n conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 16  2064       ['conv2d_15[0][0]']              \n spose)                         )                                                                 \n                                                                                                  \n concatenate_3 (Concatenate)    (None, 128, 128, 32  0           ['conv2d_transpose_3[0][0]',     \n                                )                                 'conv2d_1[0][0]']               \n                                                                                                  \n conv2d_16 (Conv2D)             (None, 128, 128, 16  4624        ['concatenate_3[0][0]']          \n                                )                                                                 \n                                                                                                  \n dropout_8 (Dropout)            (None, 128, 128, 16  0           ['conv2d_16[0][0]']              \n                                )                                                                 \n                                                                                                  \n conv2d_17 (Conv2D)             (None, 128, 128, 16  2320        ['dropout_8[0][0]']              \n                                )                                                                 \n                                                                                                  \n conv2d_18 (Conv2D)             (None, 128, 128, 17  289         ['conv2d_17[0][0]']              \n                                )                                                                 \n                                                                                                  \n==================================================================================================\nTotal params: 1,941,089\nTrainable params: 1,941,089\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n**<font color=\"#62909d\" size=\"5\">Modelo 2 - Squeeze U-NET</font>**","metadata":{}},{"cell_type":"code","source":"\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout\nfrom keras.layers import concatenate, Conv2DTranspose, BatchNormalization\nfrom keras import backend as K\n\n\n\ndef fire_module(x, fire_id, squeeze=16, expand=64):\n    f_name = \"fire{0}/{1}\"\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n\n    x = Conv2D(squeeze, (1, 1), activation='relu', padding='same', name=f_name.format(fire_id, \"squeeze1x1\"))(x)\n    x = BatchNormalization(axis=channel_axis)(x)\n\n    left = Conv2D(expand, (1, 1), activation='relu', padding='same', name=f_name.format(fire_id, \"expand1x1\"))(x)\n    right = Conv2D(expand, (3, 3), activation='relu', padding='same', name=f_name.format(fire_id, \"expand3x3\"))(x)\n    x = concatenate([left, right], axis=channel_axis, name=f_name.format(fire_id, \"concat\"))\n    return x\n\n\ndef SqueezeUNet(inputs, num_classes=None, deconv_ksize=3, dropout=0.5, activation='sigmoid'):\n    \"\"\"SqueezeUNet is a implementation based in SqueezeNetv1.1 and unet for semantic segmentation\n    :param inputs: input layer.\n    :param num_classes: number of classes.\n    :param deconv_ksize: (width and height) or integer of the 2D deconvolution window.\n    :param dropout: dropout rate\n    :param activation: type of activation at the top layer.\n    :returns: SqueezeUNet model\n    \"\"\"\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    if num_classes is None:\n        num_classes = K.int_shape(inputs)[channel_axis]\n\n    x01 = Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu', name='conv1')(inputs)\n    x02 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1', padding='same')(x01)\n\n    x03 = fire_module(x02, fire_id=2, squeeze=16, expand=64)\n    x04 = fire_module(x03, fire_id=3, squeeze=16, expand=64)\n    x05 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3', padding=\"same\")(x04)\n\n    x06 = fire_module(x05, fire_id=4, squeeze=32, expand=128)\n    x07 = fire_module(x06, fire_id=5, squeeze=32, expand=128)\n    x08 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5', padding=\"same\")(x07)\n\n    x09 = fire_module(x08, fire_id=6, squeeze=48, expand=192)\n    x10 = fire_module(x09, fire_id=7, squeeze=48, expand=192)\n    x11 = fire_module(x10, fire_id=8, squeeze=64, expand=256)\n    x12 = fire_module(x11, fire_id=9, squeeze=64, expand=256)\n\n    if dropout != 0.0:\n        x12 = Dropout(dropout)(x12)\n\n    up1 = concatenate([\n        Conv2DTranspose(192, deconv_ksize, strides=(1, 1), padding='same')(x12),\n        x10,\n    ], axis=channel_axis)\n    up1 = fire_module(up1, fire_id=10, squeeze=48, expand=192)\n\n    up2 = concatenate([\n        Conv2DTranspose(128, deconv_ksize, strides=(1, 1), padding='same')(up1),\n        x08,\n    ], axis=channel_axis)\n    up2 = fire_module(up2, fire_id=11, squeeze=32, expand=128)\n\n    up3 = concatenate([\n        Conv2DTranspose(64, deconv_ksize, strides=(2, 2), padding='same')(up2),\n        x05,\n    ], axis=channel_axis)\n    up3 = fire_module(up3, fire_id=12, squeeze=16, expand=64)\n\n    up4 = concatenate([\n        Conv2DTranspose(32, deconv_ksize, strides=(2, 2), padding='same')(up3),\n        x02,\n    ], axis=channel_axis)\n    up4 = fire_module(up4, fire_id=13, squeeze=16, expand=32)\n    up4 = UpSampling2D(size=(2, 2))(up4)\n\n    x = concatenate([up4, x01], axis=channel_axis)\n    x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(num_classes, (1, 1), activation=activation)(x)\n\n    return Model(inputs=inputs, outputs=x)\n   ","metadata":{"execution":{"iopub.status.busy":"2023-08-15T20:55:02.837711Z","iopub.execute_input":"2023-08-15T20:55:02.838162Z","iopub.status.idle":"2023-08-15T20:55:11.622656Z","shell.execute_reply.started":"2023-08-15T20:55:02.83811Z","shell.execute_reply":"2023-08-15T20:55:11.621382Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import Input\n\ninputs = Input((SIZE_X, SIZE_Y, IMG_CHANNELS))\nmodel = SqueezeUNet(inputs, num_classes=NUM_CLASSES, deconv_ksize=3)\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.005)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-15T20:55:30.110538Z","iopub.execute_input":"2023-08-15T20:55:30.111442Z","iopub.status.idle":"2023-08-15T20:55:36.004838Z","shell.execute_reply.started":"2023-08-15T20:55:30.1114Z","shell.execute_reply":"2023-08-15T20:55:36.003866Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n conv1 (Conv2D)                 (None, 64, 64, 64)   640         ['input_1[0][0]']                \n                                                                                                  \n pool1 (MaxPooling2D)           (None, 32, 32, 64)   0           ['conv1[0][0]']                  \n                                                                                                  \n fire2/squeeze1x1 (Conv2D)      (None, 32, 32, 16)   1040        ['pool1[0][0]']                  \n                                                                                                  \n batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['fire2/squeeze1x1[0][0]']       \n alization)                                                                                       \n                                                                                                  \n fire2/expand1x1 (Conv2D)       (None, 32, 32, 64)   1088        ['batch_normalization[0][0]']    \n                                                                                                  \n fire2/expand3x3 (Conv2D)       (None, 32, 32, 64)   9280        ['batch_normalization[0][0]']    \n                                                                                                  \n fire2/concat (Concatenate)     (None, 32, 32, 128)  0           ['fire2/expand1x1[0][0]',        \n                                                                  'fire2/expand3x3[0][0]']        \n                                                                                                  \n fire3/squeeze1x1 (Conv2D)      (None, 32, 32, 16)   2064        ['fire2/concat[0][0]']           \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['fire3/squeeze1x1[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n fire3/expand1x1 (Conv2D)       (None, 32, 32, 64)   1088        ['batch_normalization_1[0][0]']  \n                                                                                                  \n fire3/expand3x3 (Conv2D)       (None, 32, 32, 64)   9280        ['batch_normalization_1[0][0]']  \n                                                                                                  \n fire3/concat (Concatenate)     (None, 32, 32, 128)  0           ['fire3/expand1x1[0][0]',        \n                                                                  'fire3/expand3x3[0][0]']        \n                                                                                                  \n pool3 (MaxPooling2D)           (None, 16, 16, 128)  0           ['fire3/concat[0][0]']           \n                                                                                                  \n fire4/squeeze1x1 (Conv2D)      (None, 16, 16, 32)   4128        ['pool3[0][0]']                  \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 16, 16, 32)  128         ['fire4/squeeze1x1[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n fire4/expand1x1 (Conv2D)       (None, 16, 16, 128)  4224        ['batch_normalization_2[0][0]']  \n                                                                                                  \n fire4/expand3x3 (Conv2D)       (None, 16, 16, 128)  36992       ['batch_normalization_2[0][0]']  \n                                                                                                  \n fire4/concat (Concatenate)     (None, 16, 16, 256)  0           ['fire4/expand1x1[0][0]',        \n                                                                  'fire4/expand3x3[0][0]']        \n                                                                                                  \n fire5/squeeze1x1 (Conv2D)      (None, 16, 16, 32)   8224        ['fire4/concat[0][0]']           \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 16, 16, 32)  128         ['fire5/squeeze1x1[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n fire5/expand1x1 (Conv2D)       (None, 16, 16, 128)  4224        ['batch_normalization_3[0][0]']  \n                                                                                                  \n fire5/expand3x3 (Conv2D)       (None, 16, 16, 128)  36992       ['batch_normalization_3[0][0]']  \n                                                                                                  \n fire5/concat (Concatenate)     (None, 16, 16, 256)  0           ['fire5/expand1x1[0][0]',        \n                                                                  'fire5/expand3x3[0][0]']        \n                                                                                                  \n pool5 (MaxPooling2D)           (None, 8, 8, 256)    0           ['fire5/concat[0][0]']           \n                                                                                                  \n fire6/squeeze1x1 (Conv2D)      (None, 8, 8, 48)     12336       ['pool5[0][0]']                  \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 8, 8, 48)    192         ['fire6/squeeze1x1[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n fire6/expand1x1 (Conv2D)       (None, 8, 8, 192)    9408        ['batch_normalization_4[0][0]']  \n                                                                                                  \n fire6/expand3x3 (Conv2D)       (None, 8, 8, 192)    83136       ['batch_normalization_4[0][0]']  \n                                                                                                  \n fire6/concat (Concatenate)     (None, 8, 8, 384)    0           ['fire6/expand1x1[0][0]',        \n                                                                  'fire6/expand3x3[0][0]']        \n                                                                                                  \n fire7/squeeze1x1 (Conv2D)      (None, 8, 8, 48)     18480       ['fire6/concat[0][0]']           \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 8, 8, 48)    192         ['fire7/squeeze1x1[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n fire7/expand1x1 (Conv2D)       (None, 8, 8, 192)    9408        ['batch_normalization_5[0][0]']  \n                                                                                                  \n fire7/expand3x3 (Conv2D)       (None, 8, 8, 192)    83136       ['batch_normalization_5[0][0]']  \n                                                                                                  \n fire7/concat (Concatenate)     (None, 8, 8, 384)    0           ['fire7/expand1x1[0][0]',        \n                                                                  'fire7/expand3x3[0][0]']        \n                                                                                                  \n fire8/squeeze1x1 (Conv2D)      (None, 8, 8, 64)     24640       ['fire7/concat[0][0]']           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 8, 8, 64)    256         ['fire8/squeeze1x1[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n fire8/expand1x1 (Conv2D)       (None, 8, 8, 256)    16640       ['batch_normalization_6[0][0]']  \n                                                                                                  \n fire8/expand3x3 (Conv2D)       (None, 8, 8, 256)    147712      ['batch_normalization_6[0][0]']  \n                                                                                                  \n fire8/concat (Concatenate)     (None, 8, 8, 512)    0           ['fire8/expand1x1[0][0]',        \n                                                                  'fire8/expand3x3[0][0]']        \n                                                                                                  \n fire9/squeeze1x1 (Conv2D)      (None, 8, 8, 64)     32832       ['fire8/concat[0][0]']           \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 8, 8, 64)    256         ['fire9/squeeze1x1[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n fire9/expand1x1 (Conv2D)       (None, 8, 8, 256)    16640       ['batch_normalization_7[0][0]']  \n                                                                                                  \n fire9/expand3x3 (Conv2D)       (None, 8, 8, 256)    147712      ['batch_normalization_7[0][0]']  \n                                                                                                  \n fire9/concat (Concatenate)     (None, 8, 8, 512)    0           ['fire9/expand1x1[0][0]',        \n                                                                  'fire9/expand3x3[0][0]']        \n                                                                                                  \n dropout (Dropout)              (None, 8, 8, 512)    0           ['fire9/concat[0][0]']           \n                                                                                                  \n conv2d_transpose (Conv2DTransp  (None, 8, 8, 192)   884928      ['dropout[0][0]']                \n ose)                                                                                             \n                                                                                                  \n concatenate (Concatenate)      (None, 8, 8, 576)    0           ['conv2d_transpose[0][0]',       \n                                                                  'fire7/concat[0][0]']           \n                                                                                                  \n fire10/squeeze1x1 (Conv2D)     (None, 8, 8, 48)     27696       ['concatenate[0][0]']            \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 8, 8, 48)    192         ['fire10/squeeze1x1[0][0]']      \n rmalization)                                                                                     \n                                                                                                  \n fire10/expand1x1 (Conv2D)      (None, 8, 8, 192)    9408        ['batch_normalization_8[0][0]']  \n                                                                                                  \n fire10/expand3x3 (Conv2D)      (None, 8, 8, 192)    83136       ['batch_normalization_8[0][0]']  \n                                                                                                  \n fire10/concat (Concatenate)    (None, 8, 8, 384)    0           ['fire10/expand1x1[0][0]',       \n                                                                  'fire10/expand3x3[0][0]']       \n                                                                                                  \n conv2d_transpose_1 (Conv2DTran  (None, 8, 8, 128)   442496      ['fire10/concat[0][0]']          \n spose)                                                                                           \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 8, 8, 384)    0           ['conv2d_transpose_1[0][0]',     \n                                                                  'pool5[0][0]']                  \n                                                                                                  \n fire11/squeeze1x1 (Conv2D)     (None, 8, 8, 32)     12320       ['concatenate_1[0][0]']          \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 8, 8, 32)    128         ['fire11/squeeze1x1[0][0]']      \n rmalization)                                                                                     \n                                                                                                  \n fire11/expand1x1 (Conv2D)      (None, 8, 8, 128)    4224        ['batch_normalization_9[0][0]']  \n                                                                                                  \n fire11/expand3x3 (Conv2D)      (None, 8, 8, 128)    36992       ['batch_normalization_9[0][0]']  \n                                                                                                  \n fire11/concat (Concatenate)    (None, 8, 8, 256)    0           ['fire11/expand1x1[0][0]',       \n                                                                  'fire11/expand3x3[0][0]']       \n                                                                                                  \n conv2d_transpose_2 (Conv2DTran  (None, 16, 16, 64)  147520      ['fire11/concat[0][0]']          \n spose)                                                                                           \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 16, 16, 192)  0           ['conv2d_transpose_2[0][0]',     \n                                                                  'pool3[0][0]']                  \n                                                                                                  \n fire12/squeeze1x1 (Conv2D)     (None, 16, 16, 16)   3088        ['concatenate_2[0][0]']          \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 16, 16, 16)  64          ['fire12/squeeze1x1[0][0]']      \n ormalization)                                                                                    \n                                                                                                  \n fire12/expand1x1 (Conv2D)      (None, 16, 16, 64)   1088        ['batch_normalization_10[0][0]'] \n                                                                                                  \n fire12/expand3x3 (Conv2D)      (None, 16, 16, 64)   9280        ['batch_normalization_10[0][0]'] \n                                                                                                  \n fire12/concat (Concatenate)    (None, 16, 16, 128)  0           ['fire12/expand1x1[0][0]',       \n                                                                  'fire12/expand3x3[0][0]']       \n                                                                                                  \n conv2d_transpose_3 (Conv2DTran  (None, 32, 32, 32)  36896       ['fire12/concat[0][0]']          \n spose)                                                                                           \n                                                                                                  \n concatenate_3 (Concatenate)    (None, 32, 32, 96)   0           ['conv2d_transpose_3[0][0]',     \n                                                                  'pool1[0][0]']                  \n                                                                                                  \n fire13/squeeze1x1 (Conv2D)     (None, 32, 32, 16)   1552        ['concatenate_3[0][0]']          \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 32, 32, 16)  64          ['fire13/squeeze1x1[0][0]']      \n ormalization)                                                                                    \n                                                                                                  \n fire13/expand1x1 (Conv2D)      (None, 32, 32, 32)   544         ['batch_normalization_11[0][0]'] \n                                                                                                  \n fire13/expand3x3 (Conv2D)      (None, 32, 32, 32)   4640        ['batch_normalization_11[0][0]'] \n                                                                                                  \n fire13/concat (Concatenate)    (None, 32, 32, 64)   0           ['fire13/expand1x1[0][0]',       \n                                                                  'fire13/expand3x3[0][0]']       \n                                                                                                  \n up_sampling2d (UpSampling2D)   (None, 64, 64, 64)   0           ['fire13/concat[0][0]']          \n                                                                                                  \n concatenate_4 (Concatenate)    (None, 64, 64, 128)  0           ['up_sampling2d[0][0]',          \n                                                                  'conv1[0][0]']                  \n                                                                                                  \n conv2d (Conv2D)                (None, 64, 64, 64)   73792       ['concatenate_4[0][0]']          \n                                                                                                  \n up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 64  0          ['conv2d[0][0]']                 \n                                )                                                                 \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 128, 128, 17  1105        ['up_sampling2d_1[0][0]']        \n                                )                                                                 \n                                                                                                  \n==================================================================================================\nTotal params: 2,503,777\nTrainable params: 2,502,913\nNon-trainable params: 864\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**<font color=\"#62909d\" size=\"5\">Batch Generator</font>**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nimport json\n\ndef batch_generator(Train_df,batch_size,\n                    steps):\n    idx=1\n    while True: \n        yield load_data(Train_df,idx-1,batch_size)## Yields data\n        if idx<=steps:\n            idx+=1\n        else:\n            idx=1\n            \ndef load_data(Train_df,idx,\n              batch_size):\n    n_classes = 17\n\n    df = pd.read_csv(\n                  Train_df, skiprows=idx*batch_size,\n                  nrows=batch_size)\n    \n    x = [] \n    y = []\n    \n    for i in range(0, batch_size):\n        x.append(json.loads(df.iloc[i,0]))\n        y.append(json.loads(df.iloc[i,1]))\n    \n    y = np.asarray(y)\n    train_masks_cat = to_categorical(y, num_classes=n_classes)\n    y_train_cat = train_masks_cat.reshape((y.shape[0], y.shape[1], y.shape[2], n_classes))\n    \n    return (np.asarray(x), y_train_cat)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T16:04:57.452635Z","iopub.execute_input":"2023-08-16T16:04:57.453018Z","iopub.status.idle":"2023-08-16T16:04:57.46276Z","shell.execute_reply.started":"2023-08-16T16:04:57.452987Z","shell.execute_reply":"2023-08-16T16:04:57.461626Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nfrom keras.models import Sequential \nfrom keras.layers import Dense, Activation\nbatch_size = 15 \nnb_epoch = 10\n\n# Objetos gerados para treino e validação\nsteps_per_epoch=np.ceil(7000/batch_size)\nvalidation_steps=np.ceil(3000/batch_size)\n\nmy_training_batch_generator = batch_generator('/kaggle/input/road-mapper-dataset-csv/train_data.csv', 16,steps_per_epoch)\nmy_validation_batch_generator = batch_generator('/kaggle/input/road-mapper-dataset-csv/train_data.csv', 16,validation_steps)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-16T16:04:11.489578Z","iopub.execute_input":"2023-08-16T16:04:11.490128Z","iopub.status.idle":"2023-08-16T16:04:11.496766Z","shell.execute_reply.started":"2023-08-16T16:04:11.49008Z","shell.execute_reply":"2023-08-16T16:04:11.495609Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n\nimport pandas as pd\n\nhistory = model.fit(my_training_batch_generator,\n                    epochs=nb_epoch,\n                    steps_per_epoch=steps_per_epoch,\n                    verbose=1, \n                    validation_data=my_validation_batch_generator,\n                    validation_steps=validation_steps,\n                    shuffle=True,\n                    use_multiprocessing=True)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LmcYufmuaeUz","outputId":"1e547c95-01a1-4ec2-a5da-b321bc959826","execution":{"iopub.status.busy":"2023-08-16T16:05:09.821713Z","iopub.execute_input":"2023-08-16T16:05:09.822126Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2023-08-16 16:05:14.429820: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inU-Net/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"467/467 [==============================] - 3413s 7s/step - loss: 1.3435 - categorical_accuracy: 0.6936 - val_loss: 1.1815 - val_categorical_accuracy: 0.6971\nEpoch 2/10\n467/467 [==============================] - 3336s 7s/step - loss: 1.0818 - categorical_accuracy: 0.6970 - val_loss: 1.1372 - val_categorical_accuracy: 0.6971\nEpoch 3/10\n467/467 [==============================] - 3298s 7s/step - loss: 1.0765 - categorical_accuracy: 0.6970 - val_loss: 1.1652 - val_categorical_accuracy: 0.6971\nEpoch 4/10\n467/467 [==============================] - 3285s 7s/step - loss: 1.0718 - categorical_accuracy: 0.6970 - val_loss: 1.1243 - val_categorical_accuracy: 0.6971\nEpoch 5/10\n467/467 [==============================] - 3410s 7s/step - loss: 1.0704 - categorical_accuracy: 0.6971 - val_loss: 1.0660 - val_categorical_accuracy: 0.6971\nEpoch 6/10\n467/467 [==============================] - 3345s 7s/step - loss: 1.0662 - categorical_accuracy: 0.6971 - val_loss: 1.0581 - val_categorical_accuracy: 0.6971\nEpoch 7/10\n467/467 [==============================] - 3316s 7s/step - loss: 1.0642 - categorical_accuracy: 0.6971 - val_loss: 1.0608 - val_categorical_accuracy: 0.6971\nEpoch 8/10\n467/467 [==============================] - 3690s 8s/step - loss: 1.0617 - categorical_accuracy: 0.6970 - val_loss: 1.0545 - val_categorical_accuracy: 0.6971\nEpoch 9/10\n467/467 [==============================] - 6905s 15s/step - loss: 1.0598 - categorical_accuracy: 0.6970 - val_loss: 1.0521 - val_categorical_accuracy: 0.6971\nEpoch 10/10\n467/467 [==============================] - ETA: 0s - loss: 1.0574 - categorical_accuracy: 0.6971 ","output_type":"stream"},{"name":"stderr","text":"Process Keras_worker_ForkPoolWorker-4:\nProcess Keras_worker_ForkPoolWorker-7:\n","output_type":"stream"}]},{"cell_type":"code","source":"# Salvando o modelo\nmodel.save('multiclass_road_mapper')\n","metadata":{"id":"KQ_NuTmlafmh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salvando os resultados\nimport pickle\ntry:  \n    arquivo = open(\"results.bin\", \"wb\")\n    pickle.dump(results, arquivo)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo results.\")\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salvando os resultados\nimport pickle\ntry:  \n    arquivo = open(\"results.json\", \"w\")\n    json.dump(results, arquivo, indent=4)\n    arquivo.close()\nexcept:\n    print(\"Problemas com o arquivo results json.\")\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_file('/kaggle/working', 'out')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"chap5\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:40px;text-align:center\">Analisando os Resultados</h1></div>","metadata":{}},{"cell_type":"code","source":"\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(epochs, acc, 'y', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"id":"iVibZ6c1ao7P","outputId":"c9fb159a-53cd-456a-aff2-b0af62640283"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load do modelo salvo\nfrom keras.models import load_model\nmodel = load_model(\"/content/drive/MyDrive/Colab Notebooks/saved_models/tutorial119_sandstone_50epochs.hdf5\", compile=False)","metadata":{"id":"RO7ACKoBapui"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"chap6\"><h1 style=\"color:white;background:#62909d;border-radius:5px;padding:30px;font-family:'Sans-Serif', cursive;font-size:40px;text-align:center\">Realizando testes (Predict)</h1></div>","metadata":{}},{"cell_type":"code","source":"y_pred=model.predict(X_test)","metadata":{"id":"UNuftNH18ZoY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_SF6IU38cxw","outputId":"b1a4ac40-a3e9-40e7-95d7-b249ed13f6c6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_argmax=np.argmax(y_pred, axis=3)\ny_pred_argmax.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drpgFz-SjPq3","outputId":"6934927b-6610-4784-b8dd-f75c7c320a78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using built in keras function\nfrom keras.metrics import MeanIoU\nn_classes = 4\nIOU_keras = MeanIoU(num_classes=n_classes)  \nIOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\nprint(\"Mean IoU =\", IOU_keras.result().numpy())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5panJLTGawJx","outputId":"d195ca02-d42d-4388-a587-4ce8d7a7fcb7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To calculate I0U for each class...\nvalues = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\nprint(values)\nclass1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\nclass2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\nclass3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\nclass4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n\nprint(\"IoU for class1 is: \", class1_IoU)\nprint(\"IoU for class2 is: \", class2_IoU)\nprint(\"IoU for class3 is: \", class3_IoU)\nprint(\"IoU for class4 is: \", class4_IoU)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgHHa8q9axAx","outputId":"de3de859-7ca6-4f81-8d2d-a97501f6f3a1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict on a few images\n#model = get_model()\n#model.load_weights('???.hdf5')  \nimport random\ntest_img_number = random.randint(0, len(X_test)-1)\ntest_img = X_test[test_img_number]\nground_truth=y_test[test_img_number]\ntest_img_norm=test_img[:,:,0][:,:,None]\ntest_img_input=np.expand_dims(test_img_norm, 0)\nprediction = (model.predict(test_img_input))\npredicted_img=np.argmax(prediction, axis=3)[0,:,:]\n\n\nplt.figure(figsize=(12, 8))\nplt.subplot(231)\nplt.title('Testing Image')\nplt.imshow(test_img[:,:,0], cmap='gray')\nplt.subplot(232)\nplt.title('Testing Label')\nplt.imshow(ground_truth[:,:,0], cmap='jet')\nplt.subplot(233)\nplt.title('Prediction on test image')\nplt.imshow(predicted_img, cmap='jet')\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"zW-IdHfAa2f6","outputId":"68a6eb40-1f74-4f90-b489-6375a473151f"},"execution_count":null,"outputs":[]}]}